{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def lick_counter(trial_duration, lick_start, lick_end, licks):\n",
    "    \"\"\"\n",
    "    Counts the number of licks that occur during a specified time window and calculates the fraction of licks that \n",
    "    occur at the reward onset time.\n",
    "    \n",
    "    PARAMETERS:\n",
    "        trial_duration (float): The duration of the trial in seconds.\n",
    "        lick_start (int): The timepoint at which the reward was presented.\n",
    "        lick_end (int): The timepoint at which the reward window ends.\n",
    "        licks (numpy array): A numpy array of shape (m,) containing the timepoints at which licks occurred.\n",
    "    \n",
    "    RETURNS:\n",
    "        tuple: A tuple containing the lick count and fraction of licks at the reward onset time.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the lick counter.\n",
    "    lick_counter = 0 \n",
    "    \n",
    "    # Iterate through each row in the dataframe.\n",
    "    for i in range(len(lick_start)):\n",
    "        # Check if the lick time falls within the reward window.\n",
    "        for lick in licks:\n",
    "            if lick_start[i] <= lick <= lick_end[i]:\n",
    "                lick_counter += 1\n",
    "    \n",
    "    # Compute the fraction of licks that occur at the reward onset time.\n",
    "    reward_licks = lick_counter / len(licks) * 100\n",
    "    \n",
    "    return lick_counter, reward_licks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_feature_position(timestamp, position, min_pos, max_pos):\n",
    "    '''\n",
    "    Takes the time of an event (in index), the position array, the min of the trial position and the max\n",
    "    of the trial position, returns the normalized position of the event.\n",
    "\n",
    "    PARAMETERS:\n",
    "    timestamp (int) : timestamp of the event (in index).\n",
    "    position (numpy.ndarray) : position array.\n",
    "    min_pos (float) : minimum position value of the trial.\n",
    "    max_pos (float) : maximum position value of the trial.\n",
    "\n",
    "    RETURNS:\n",
    "    norm_pos (float): normalized position of the event.\n",
    "    '''\n",
    "    \n",
    "    # Extract the position value at the given timestamp.\n",
    "    pos = position[int(timestamp)]\n",
    "\n",
    "    # Calculate the normalized position of the event based on the min and max position values.\n",
    "    norm_pos = (pos - min_pos) / (max_pos - min_pos)\n",
    "    \n",
    "    # Return the normalized position value.\n",
    "    return norm_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def position_event_histogram(b_data, trial_data):\n",
    "    '''\n",
    "    Plot a histogram of the normalized position with markers for specific events:\n",
    "    Reward zone onset, Tunnel1 onset, Sound onset\n",
    "\n",
    "    PARAMETERS:\n",
    "    b_data (pandas.DataFrame) : a DataFrame containing the behavior data.\n",
    "    trial_data (pandas.DataFrame) : a DataFrame containing the trial data.\n",
    "\n",
    "    RETURNS:\n",
    "    A histogram plot of the normalized position data with markers for the event onsets.\n",
    "    '''\n",
    "    \n",
    "    # Get the position data from the behavior data DataFrame.\n",
    "    position = b_data['position']\n",
    "\n",
    "    # Initialize lists to store the positions of the event onsets.\n",
    "    rz_onsets = []\n",
    "    tunnel1_onsets = []\n",
    "    sound_onsets = []\n",
    "\n",
    "    # Loop through each trial in the trial data DataFrame.\n",
    "    for i in range(len(trial_data)):\n",
    "\n",
    "        # Get the current trial row.\n",
    "        row = trial_data.iloc[i]\n",
    "\n",
    "        # Extract the onset and offset times for the current trial segment.\n",
    "        onset = row['env_onset'].astype(int)\n",
    "        offset = row['tunnel2_offset']\n",
    "\n",
    "        # Get the position data for the current trial segment.\n",
    "        pos_segment = position[onset:offset]\n",
    "\n",
    "        # Compute the minimum and maximum positions in the current trial segment.\n",
    "        min_pos = np.min(pos_segment)\n",
    "        max_pos = np.max(pos_segment)\n",
    "\n",
    "        # Compute the positions of the reward zone onset, tunnel 1 onset, and sound onset.\n",
    "        rz_pos = compute_feature_position(row['reward_zone_onset'], position, min_pos, max_pos)\n",
    "        rz_onsets.append(rz_pos)\n",
    "\n",
    "        t1_pos = compute_feature_position(row['tunnel1_onset'], position, min_pos, max_pos)\n",
    "        tunnel1_onsets.append(t1_pos)\n",
    "\n",
    "        if pd.notnull(row['sound_onset']): # Skip NaNs.\n",
    "            sound_pos = compute_feature_position(int(row['sound_onset']), position, min_pos, max_pos)\n",
    "            sound_onsets.append(sound_pos)\n",
    "\n",
    "        # Normalize the position data for the current trial segment.\n",
    "        pos_segment = (pos_segment - np.min(pos_segment)) / (np.max(pos_segment) - np.min(pos_segment))\n",
    "\n",
    "        # Concatenate the normalized position data for the current trial segment with the previous segments.\n",
    "        if i == 0:\n",
    "            norm_pos = pos_segment\n",
    "        else:\n",
    "            norm_pos = np.hstack([norm_pos, pos_segment])\n",
    "\n",
    "    # Plot a histogram of the normalized position data with markers for the event onsets.\n",
    "    plt.hist(norm_pos, bins=30, density=True)\n",
    "    plt.axvline(x=np.mean(rz_onsets), c='r')\n",
    "    plt.axvline(x=np.mean(tunnel1_onsets), c='g')\n",
    "    plt.axvline(x=np.nanmean(sound_onsets), c='m')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compute_velocity(b_data, dt=1./1000., pos_sigma=2, vel_sigma=50, vel_win=10000, vel_smooth=100):\n",
    "    \"\"\"\n",
    "    Computes the velocity matrix from the position data in b_data using Gaussian filtering.\n",
    "\n",
    "    PARAMETERS:\n",
    "    b_data (dict): A dictionary containing the position data as a numpy array under the key 'position'.\n",
    "    dt (float, optional): The time step between position measurements, in seconds. Default of recording apparatus is 1/1000 Hz.\n",
    "    pos_sigma (float, optional): The standard deviation of the Gaussian kernel for smoothing the position data.\n",
    "                                     Default is 2.\n",
    "    vel_sigma (float, optional): The standard deviation of the Gaussian kernel for smoothing the velocity data.\n",
    "                                     Default is 50.\n",
    "    vel_win (int, optional): The size of the window for computing the velocity, in samples. Default is 10000.\n",
    "    vel_smooth (int, optional): The size of the Gaussian smoothing kernel for the velocity data. Default is 100.\n",
    "\n",
    "    RETURNS:\n",
    "    tuple: A tuple containing the velocity matrix and a plot of the velocity data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Apply Gaussian smoothing to the position data to reduce noise.\n",
    "    pos = gaussian_filter1d(b_data['position'].astype(float), sigma=pos_sigma)\n",
    "    \n",
    "    # Calculate the discrete difference between adjacent position samples to obtain the velocity.\n",
    "    vel = np.diff(pos) / dt\n",
    "    \n",
    "    # Apply Gaussian smoothing to the velocity data to further reduce noise.\n",
    "    vel = gaussian_filter1d(vel, sigma=vel_sigma)\n",
    "    \n",
    "    # Plot a window of the velocity data with additional Gaussian smoothing for visualization.\n",
    "    plt.plot(gaussian_filter1d(vel[:vel_win], sigma=vel_smooth))\n",
    "    \n",
    "    # Add labels and title to the velocity plot.\n",
    "    plt.xlabel('Frame number')\n",
    "    plt.ylabel('Velocity (m/s)')\n",
    "    #plt.title('Velocity plot')\n",
    "    \n",
    "    # Show the plot.\n",
    "    plt.show()\n",
    "    \n",
    "    # Return the velocity data.\n",
    "    return vel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import binned_statistic\n",
    "\n",
    "def pos_vel_scatterplot(norm_pos, vel, nbins=50):\n",
    "    \"\"\"\n",
    "    Create a scatter plot of the relationship between position and velocity\n",
    "    using binned statistics.\n",
    "\n",
    "    PARAMETERS:\n",
    "    norm_pos : array-like\n",
    "            The normalized positions.\n",
    "    vel : array-like\n",
    "            The velocities.\n",
    "    nbins : int, optional\n",
    "            The number of bins to use for the scatter plot (default=50).\n",
    "\n",
    "    RETURNS:\n",
    "    A scatterplot with graph between datapoints to visualize the relationship between position and velocity.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate binned statistics of velocity as a function of position.\n",
    "    avg_vel, edges, _ = binned_statistic(norm_pos, vel, bins=nbins)\n",
    "\n",
    "    # Calculate centers of each bin.\n",
    "    centers = [(edges[i+1] + edges[i]) / 2 for i in range(len(edges) - 1)]\n",
    "\n",
    "    # Plot scatter plot with x-axis labeled \"Position\", y-axis labeled \"Velocity\",\n",
    "    # and title \"Position vs Velocity Scatterplot\".\n",
    "    plt.plot(centers, avg_vel)\n",
    "    plt.xlabel('Position')\n",
    "    plt.ylabel('Velocity')\n",
    "    #plt.title('Position vs Velocity Scatterplot')\n",
    "\n",
    "    # Display the scatter plot.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def computed_sliced_matrix(trial_matrix, vel, t_on, t_off):\n",
    "    \"\"\"\n",
    "    Computes a 2D array (trial x timepoints) of velocity values for a given time window around a sound onset.\n",
    "    for each trial in a trial_matrix dataframe.\n",
    "    \n",
    "    PARAMETERS:\n",
    "    trial_matrix (pandas.DataFrame): a dataframe containing the trial data.\n",
    "    vel (numpy.ndarray): a 1D array of velocity values.\n",
    "    t_on (int): the number of milliseconds before the sound onset to include in the velocity timecourse.\n",
    "    t_off (int): the number of milliseconds after the sound onset to include in the velocity timecourse.\n",
    "    \n",
    "    RETURNS:\n",
    "    vel_matrix (numpy.ndarray): a 2D array of velocity values for each trial, with shape (number of trials, t_on + t_off).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the velocity matrix and count variable.\n",
    "    vel_matrix = np.zeros((len(trial_matrix), t_on + t_off))\n",
    "    count = 0\n",
    "    \n",
    "    # Cycle over the trials using integer indexing.\n",
    "    for i in range(len(trial_matrix)):\n",
    "        \n",
    "        # Get the current trial row.\n",
    "        row = trial_matrix.iloc[i]\n",
    "        \n",
    "        # Check if the row contains valid data.\n",
    "        if not np.isnan(row['sound_onset']):\n",
    "            onset = row['sound_onset'].astype(int) - t_on # 2 seconds before.\n",
    "            offset = row['sound_onset'].astype(int) + t_off # 2 seconds after.\n",
    "            trial_vel = vel[onset:offset]\n",
    "            \n",
    "            # Add the trial's velocity timecourse to the velocity matrix.\n",
    "            vel_matrix[count,:] = trial_vel\n",
    "            count += 1\n",
    "            \n",
    "    # Truncate the velocity matrix to remove rows with NaN values.\n",
    "    vel_matrix = vel_matrix[:count,:]\n",
    "    \n",
    "    return vel_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import sem\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def avg_std_sem_velocity(vel_matrix, t_on, t_off):\n",
    "    \"\"\"\n",
    "    Computes the average, standard deviation, and standard error of the mean of velocity from a velocity matrix,\n",
    "    and plots the average velocity over time with the fill_between visible.\n",
    "\n",
    "    PARAMETERS:\n",
    "    vel_matrix (numpy.ndarray): A 2D numpy array where each row represents a different trial and each column\n",
    "        represents a different time point.\n",
    "    t_on (int): The duration of the time period before sound onset, in milliseconds.\n",
    "    t_off (int): The duration of the time period after sound onset, in milliseconds.\n",
    "\n",
    "    RETURNS:\n",
    "    tuple: A tuple of 3 numpy arrays containing the average velocity, standard deviation, and standard error of\n",
    "        the mean of velocity, respectively.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute the average velocity across trials for each time point.\n",
    "    avg_vel = np.mean(vel_matrix, axis=0)\n",
    "\n",
    "    # Compute the standard deviation of velocity across trials for each time point.\n",
    "    std_vel = np.std(vel_matrix, axis=0)\n",
    "\n",
    "    # Compute the standard error of the mean of velocity across trials for each time point.\n",
    "    sem_vel = sem(vel_matrix, axis=0)\n",
    "\n",
    "    # Generate an array of time points in seconds.\n",
    "    t = np.linspace(-t_on / 1000, t_off / 1000, t_on + t_off)  \n",
    "\n",
    "    # Plot the average velocity over time.\n",
    "    plt.plot(t, avg_vel)\n",
    "\n",
    "    # Fill the area between the upper and lower bounds of the standard error of the mean.\n",
    "    plt.fill_between(t, avg_vel - sem_vel, avg_vel + sem_vel, alpha=0.5)\n",
    "\n",
    "    # Draw a red vertical line at the time of sound onset.\n",
    "    plt.axvline(x=0, c='r')\n",
    "\n",
    "    # Show the plot.\n",
    "    plt.show()\n",
    "\n",
    "    # Return the average, standard deviation, and standard error of the mean of velocity as a tuple.\n",
    "    return avg_vel, std_vel, sem_vel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "def ttest_speed_distribution(vel_matrix, t_on, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Computes the t-test for the speed distribution before and after the sound onset.\n",
    "    \n",
    "    PARAMETERS:\n",
    "    vel_matrix (numpy.ndarray): a 2D array of velocity values for each trial, with shape (number of trials, t_on + t_off).\n",
    "    alpha: can choose a significance level by passing a value for the alpha parameter when calling the function.\n",
    "    \n",
    "    RETURNS:\n",
    "    t (float): the t-test statistic.\n",
    "    p (float): the p-value.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Slice vel_matrix at sound onset.\n",
    "    vel_before = vel_matrix[:, :t_on].flatten() # Selects all rows and the first t_on columns of the vel_matrix, which corresponds to the velocity values before the sound onset. \n",
    "    vel_after = vel_matrix[:, t_on:].flatten() # Selects all rows and the columns starting from the t_on-th column of the vel_matrix, which corresponds to the velocity values after the sound onset. \n",
    "    \n",
    "    # Compute t-test between vel_before and vel_after.\n",
    "    t_stat, p_val = ttest_ind(vel_before, vel_after)\n",
    "    \n",
    "    # Check if the difference between the speed distributions before and after the sound onset is statistically significant.\n",
    "    if p_val < alpha:\n",
    "        # If p-value is less than the significance level, reject the null hypothesis and print message indicating statistical significance.\n",
    "        print(\"The difference between the speed distributions before and after the sound onset is statistically significant (p < {:.4f})\".format(alpha))\n",
    "        # If p-value is greater than or equal to the significance level, fail to reject the null hypothesis and print message indicating no statistical significance.\n",
    "    else:\n",
    "        print(\"There is no statistically significant difference between the speed distributions before and after the sound onset (p = {:.4f})\".format(p_val))\n",
    "    \n",
    "    return t_stat, p_val"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
